"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[2946],{414:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2025-09-publication-example copy","metadata":{"permalink":"/publications/2025-09-publication-example copy","source":"@site/publications/2025-09-publication-example copy.md","title":"A Lightweight Recurrent Architecture for Robust Urban Traffic Forecasting With Missing Data","description":"Link//ieeexplore.ieee.org/document/11162586","date":"2025-09-24T15:12:37.000Z","tags":[{"inline":false,"label":"Selected Publication","permalink":"/publications/tags/main","description":"Main publications chosen by myself."}],"readingTime":0.985,"hasTruncateMarker":true,"authors":[{"name":"Lucas Bi\xe9chy","title":"Research Scientist @ Inria","url":"https://biechy.github.io","page":{"permalink":"/publications/authors/all-biechy-articles"},"socials":{"Email":"mailto:lucas.biechy@inria.fr","linkedin":"https://www.linkedin.com/in/biechy/","github":"https://github.com/biechy"},"description":"Host of this website. I am a PhD student at Inria working on NLP for privacy. I am interest in the links between machine learning, physics, economics and more.","imageURL":"https://github.com/biechy.png","key":"biechy"}],"frontMatter":{"title":"A Lightweight Recurrent Architecture for Robust Urban Traffic Forecasting With Missing Data","authors":["biechy"],"tags":["important"]},"unlisted":false},"content":"Link : https://ieeexplore.ieee.org/document/11162586\\n\\nReal-time traffic flow prediction plays a vital role in alleviating urban congestion and improving transportation efficiency. However, urban traffic data are often subject to sensor anomalies, missing values, and unstable model performance. To address these challenges, this paper proposes a lightweight and robust recurrent neural network architecture \x3c!-- truncate --\x3e designed to enhance the accuracy and reliability of traffic flow forecasting under data incompleteness. We introduce two enhanced recurrent models\u2014Extended Long Short-Term Memory (xLSTM) and Extended Gated Recurrent Unit (xGRU)\u2014which incorporate exponential gating mechanisms and matrix-valued memory updates. These enhancements significantly reduce model complexity and training overhead while preserving high prediction accuracy. Furthermore, a three-tier imputation strategy is proposed to handle missing data, adaptively applying linear interpolation, temporal averaging, or seasonal decomposition based on the length and characteristics of the missing intervals. Extensive experiments were conducted on a six-month multivariate traffic sensor dataset collected from Taichung City, Taiwan. The results demonstrate that xGRU achieves comparable or superior forecasting accuracy to mainstream Transformer-based models, such as Informer, Autoformer, and TFT, despite using significantly fewer parameters. These findings highlight the proposed architecture\u2019s practical potential for real-world urban traffic forecasting with enhanced efficiency, robustness, and data resilience."}]}}')}}]);